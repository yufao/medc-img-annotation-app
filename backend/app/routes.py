from flask import request, jsonify, send_file, current_app, render_template
from flask import Blueprint
import os
import sys
import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from dotenv import load_dotenv
from io import BytesIO
import logging

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ·»åŠ åç«¯ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œç”¨äºå¯¼å…¥æ•°æ®åº“å·¥å…·
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from db_utils import get_next_annotation_id

# æ•°æ®é›†ç®¡ç†å™¨
from .dataset_manager import dataset_manager


# åŠ è½½ç¯å¢ƒå˜é‡ï¼Œè¿æ¥MongoDB
load_dotenv()
MONGO_URI = os.getenv('MONGODB_URI', 'mongodb://172.20.48.1:27017/local')
MONGO_DB = os.getenv('MONGODB_DB', 'local')
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]

# é™æ€å›¾ç‰‡ç›®å½•è¯´æ˜ï¼š
# å›¾ç‰‡æ–‡ä»¶åº”æ”¾åœ¨ backend/app/static/img/ ç›®å½•ä¸‹
# å‰ç«¯ <img src="/static/img/xxx.jpg"> ä¼šè‡ªåŠ¨æ˜ å°„åˆ°è¯¥ç›®å½•
# Flask é»˜è®¤ä¼šå°† static/ ç›®å½•ä½œä¸ºé™æ€æ–‡ä»¶æ ¹ç›®å½•

# ç”¨æˆ·è§’è‰²åˆ°expert_idçš„æ˜ å°„
ROLE_TO_EXPERT_ID = {
    "admin": 0,
    "doctor": 1, 
    "student": 2
}

# ç”¨æˆ·ä¾ç„¶ç”¨mock
USERS = [
    {"username": "admin", "password": "admin123", "role": "admin"},
    {"username": "doctor", "password": "doctor123", "role": "doctor"},
    {"username": "student", "password": "student123", "role": "student"},
]
"""
æ ‡æ³¨è®°å½•è¡¨ç»“æ„ï¼š
{
    dataset_id: æ•°æ®é›†ID,
    record_id: æ ‡è®°è®°å½•å”¯ä¸€ID,
    image_id: å›¾åƒID,
    expert_id: åŒºåˆ†èº«ä»½ï¼ˆ0=çœŸå®æ ‡ç­¾ï¼Œ1=ä¸“å®¶ï¼Œ2=å®ä¹ åŒ»å¸ˆï¼Œ3=åŒ»å­¦ç”Ÿï¼‰, 
    label: æ ‡ç­¾ID,
    datetime: æ ‡æ³¨æ—¶é—´,
    tip: å¤‡æ³¨
}
"""

# å›¾åƒæ ·æœ¬è¡¨ç»“æ„ï¼š
# {
#     image_id: å›¾åƒID,
#     dataset_id: æ•°æ®é›†ID,
#     filename: æ–‡ä»¶å
# }
IMAGES = [
    # æ•°æ®é›†1 - èƒ¸ç‰‡å¼‚å¸¸æ£€æµ‹
    {"image_id": 1, "dataset_id": 1, "filename": "person1_virus_6.jpeg"},
    {"image_id": 2, "dataset_id": 1, "filename": "person1_virus_7.jpeg"},
    {"image_id": 3, "dataset_id": 1, "filename": "person1_virus_8.jpeg"},
    {"image_id": 4, "dataset_id": 1, "filename": "person1_virus_9.jpeg"},
    {"image_id": 5, "dataset_id": 1, "filename": "person3_virus_15.jpeg"},
    {"image_id": 6, "dataset_id": 1, "filename": "person3_virus_16.jpeg"},
    {"image_id": 7, "dataset_id": 1, "filename": "person3_virus_17.jpeg"},
    {"image_id": 8, "dataset_id": 1, "filename": "person8_virus_27.jpeg"},
    {"image_id": 9, "dataset_id": 1, "filename": "person8_virus_28.jpeg"},
    {"image_id": 10, "dataset_id": 1, "filename": "person10_virus_35.jpeg"},
    
    # æ•°æ®é›†2 - CTå½±åƒåˆ†æ  
    {"image_id": 11, "dataset_id": 2, "filename": "person78_bacteria_378.jpeg"},
    {"image_id": 12, "dataset_id": 2, "filename": "person78_bacteria_380.jpeg"},
    {"image_id": 13, "dataset_id": 2, "filename": "person78_bacteria_381.jpeg"},
    {"image_id": 14, "dataset_id": 2, "filename": "person78_bacteria_382.jpeg"},
    {"image_id": 15, "dataset_id": 2, "filename": "person80_bacteria_389.jpeg"},
    {"image_id": 16, "dataset_id": 2, "filename": "person80_bacteria_390.jpeg"},
    {"image_id": 17, "dataset_id": 2, "filename": "person80_bacteria_391.jpeg"},
    {"image_id": 18, "dataset_id": 2, "filename": "person80_bacteria_392.jpeg"},
    {"image_id": 19, "dataset_id": 2, "filename": "person80_bacteria_393.jpeg"},
    {"image_id": 20, "dataset_id": 2, "filename": "person78_bacteria_384.jpeg"}
]

# æ ‡ç­¾å­—å…¸è¡¨ç»“æ„ï¼š
# {
#     label_id: æ ‡ç­¾ID,
#     dataset_id: æ•°æ®é›†ID,
#     name: æ ‡ç­¾åç§°
# }
LABELS = [
    {"label_id": 1, "dataset_id": 1, "name": "æ­£å¸¸"},
    {"label_id": 2, "dataset_id": 1, "name": "å¼‚å¸¸"},
    {"label_id": 3, "dataset_id": 1, "name": "å¾…å®š"},
    {"label_id": 1, "dataset_id": 2, "name": "æ­£å¸¸"},
    {"label_id": 2, "dataset_id": 2, "name": "å¼‚å¸¸"},
    {"label_id": 3, "dataset_id": 2, "name": "å¾…å®š"}
]

ANNOTATIONS = []

bp = Blueprint('api', __name__)

def register_routes(app):
    # æ³¨å†Œè“å›¾ï¼Œå°†æ‰€æœ‰APIè·¯ç”±æŒ‚è½½åˆ°Flaskåº”ç”¨
    app.register_blueprint(bp)

@bp.route('/api/login', methods=['POST'])
def login():
    # ç”¨æˆ·ç™»å½•æ¥å£ï¼Œæ ¡éªŒç”¨æˆ·åå’Œå¯†ç ï¼Œè¿”å›ç”¨æˆ·è§’è‰²
    data = request.json
    for user in USERS:
        if user['username'] == data.get('username') and user['password'] == data.get('password'):
            return jsonify({"msg": "success", "role": user['role']}), 200
    return jsonify({"msg": "fail"}), 401

@bp.route('/api/datasets', methods=['GET'])
def get_datasets():
    """è·å–æ‰€æœ‰æ•°æ®é›†åˆ—è¡¨ï¼Œæ”¯æŒè‡ªåŠ¨æ‰«æstaticç›®å½•"""
    user_id = request.args.get('user_id')
    
    try:
        # ä½¿ç”¨æ–°çš„æ•°æ®é›†ç®¡ç†å™¨è·å–æ•°æ®é›†åˆ—è¡¨
        datasets = dataset_manager.get_datasets_list()
        
        # å¦‚æœæ²¡æœ‰å‘ç°æ•°æ®é›†ï¼Œå°è¯•ä»MongoDBè·å–
        if not datasets:
            try:
                datasets = list(db.datasets.find({}, {'_id': 0, 'id': 1, 'name': 1, 'description': 1}))
            except Exception as e:
                current_app.logger.error(f"MongoDBæŸ¥è¯¢å¤±è´¥: {e}")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®é›†ï¼Œè¿”å›æµ‹è¯•æ•°æ®é›†
        if not datasets:
            datasets = [
                {"id": 1, "name": "æµ‹è¯•æ•°æ®é›†1", "description": "èƒ¸ç‰‡å¼‚å¸¸æ£€æµ‹"},
                {"id": 2, "name": "æµ‹è¯•æ•°æ®é›†2", "description": "CTå½±åƒåˆ†æ"}
            ]
        
        current_app.logger.info(f"è¿”å›æ•°æ®é›†åˆ—è¡¨ï¼Œå…± {len(datasets)} ä¸ªæ•°æ®é›†")
        return jsonify(datasets)
        
    except Exception as e:
        current_app.logger.error(f"è·å–æ•°æ®é›†å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤æµ‹è¯•æ•°æ®é›†
        return jsonify([
            {"id": 1, "name": "æµ‹è¯•æ•°æ®é›†1", "description": "èƒ¸ç‰‡å¼‚å¸¸æ£€æµ‹"},
            {"id": 2, "name": "æµ‹è¯•æ•°æ®é›†2", "description": "CTå½±åƒåˆ†æ"}
        ])

@bp.route('/api/images_with_annotations', methods=['POST'])
def images_with_annotations():
    """è·å–æ•°æ®é›†å›¾ç‰‡å’Œæ ‡æ³¨ä¿¡æ¯ï¼Œæ”¯æŒæ–°çš„ç¼–å·ç³»ç»Ÿå’Œä¸“å±æ ‡æ³¨é›†åˆ"""
    data = request.json
    ds_id = data.get('dataset_id')
    expert_id = data.get('expert_id')
    role = data.get('role', 'student')
    include_all = data.get('include_all', False)
    page = data.get('page', 1)
    page_size = data.get('pageSize', 20)
    
    # æ ¹æ®è§’è‰²ç¡®å®šå®é™…çš„expert_id
    actual_expert_id = ROLE_TO_EXPERT_ID.get(role, 2)  # é»˜è®¤ä¸ºstudent
    
    try:
        # ç¡®ä¿ds_idä¸ºæ•´æ•°ç±»å‹
        if isinstance(ds_id, str) and ds_id.isdigit():
            ds_id = int(ds_id)
        
        # ä½¿ç”¨æ–°çš„æ•°æ®é›†ç®¡ç†å™¨è·å–å›¾ç‰‡ä¿¡æ¯
        dataset = dataset_manager.get_dataset_by_id(ds_id)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {ds_id} æœªæ‰¾åˆ°"}), 404
            
        imgs = dataset['images']
        current_app.logger.info(f"ä½¿ç”¨æ•°æ®é›†ç®¡ç†å™¨è·å–å›¾ç‰‡ï¼Œæ•°æ®é›† {ds_id}ï¼Œå›¾ç‰‡æ•°é‡: {len(imgs)}")
            
        # è·å–è¯¥æ•°æ®é›†ä¸“å±çš„æ ‡æ³¨é›†åˆ
        annotation_collection = get_annotation_collection(ds_id)
        
        # è·å–è¯¥è§’è‰²çš„æ‰€æœ‰æ ‡æ³¨
        annotations = list(annotation_collection.find({
            'expert_id': actual_expert_id
        }, {'_id': 0}))
        
        current_app.logger.info(f"ä»é›†åˆ '{annotation_collection.name}' è·å–è§’è‰² {role} çš„æ ‡æ³¨ {len(annotations)} æ¡")
        
        # åˆå¹¶å›¾ç‰‡å’Œæ ‡æ³¨ä¿¡æ¯
        result = []
        for img in imgs:
            # åœ¨Pythonç«¯è¿›è¡ŒåŒ¹é…
            ann = next((a for a in annotations if a['image_id'] == img['image_id']), None)
            
            # å¦‚æœæœ‰æ ‡æ³¨ï¼Œæ·»åŠ æ ‡ç­¾åç§°
            if ann:
                label_info = dataset_manager.get_label_info(ds_id, ann.get('label_id'))
                if label_info:
                    ann['label_name'] = label_info['name']
            
            img_data = {
                "image_id": img['image_id'], 
                "display_id": img.get('display_id', ''),
                "filename": img['filename'],
                "url": img.get('url', f"/static/{dataset['code']}/{img['filename']}"),  # ç¡®ä¿åŒ…å«å®Œæ•´URL
                "annotation": ann
            }
            
            # å¦‚æœinclude_allä¸ºFalseï¼Œåªè¿”å›æœªæ ‡æ³¨çš„å›¾ç‰‡
            if include_all or not ann:
                result.append(img_data)
        
        # åˆ†é¡µå¤„ç†
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_result = result[start_idx:end_idx]
        
        return jsonify(paginated_result)
        
    except Exception as e:
        current_app.logger.error(f"è·å–å›¾ç‰‡æ ‡æ³¨å¤±è´¥: {e}")
        return jsonify([])

# æ·»åŠ æ–°çš„APIç«¯ç‚¹ï¼šè·å–æ•°æ®é›†å›¾ç‰‡ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
@bp.route('/api/datasets/<int:dataset_id>/images', methods=['GET'])
def get_dataset_images(dataset_id):
    expert_id = request.args.get('expert_id')
    role = request.args.get('role', 'student')
    page = int(request.args.get('page', 1))
    page_size = int(request.args.get('pageSize', 20))
    
    # æ ¹æ®è§’è‰²ç¡®å®šå®é™…çš„expert_id
    actual_expert_id = ROLE_TO_EXPERT_ID.get(role, 2)
    
    try:
        # ä»MongoDBè·å–å›¾ç‰‡
        imgs = list(db.images.find({'dataset_id': dataset_id}, {'_id': 0}))
        
        # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®
        if not imgs:
            imgs = [img for img in IMAGES if img['dataset_id'] == dataset_id]
        else:
            # ä¸ºMongoDBä¸­çš„å›¾ç‰‡æ•°æ®æ·»åŠ ç¼ºå¤±çš„image_idå­—æ®µ
            for i, img in enumerate(imgs):
                if 'image_id' not in img:
                    img['image_id'] = i + 1  # ç”Ÿæˆä¸€ä¸ªç®€å•çš„image_id
        
        # è·å–æ ‡æ³¨
        annotations = list(db.annotations.find({
            'dataset_id': dataset_id,
            'expert_id': actual_expert_id
        }, {'_id': 0}))
        
        if not annotations:
            annotations = [a for a in ANNOTATIONS if a['dataset_id'] == dataset_id and a['expert_id'] == actual_expert_id]
        
        # åˆå¹¶æ•°æ®
        result = []
        for img in imgs:
            ann = next((a for a in annotations if a['image_id'] == img['image_id']), None)
            if ann:
                # åœ¨å¯¹åº”æ•°æ®é›†ä¸­æŸ¥æ‰¾æ ‡ç­¾åç§°
                label_info = next((l for l in LABELS if l['label_id'] == ann.get('label') and l['dataset_id'] == dataset_id), None)
                if label_info:
                    ann['label_name'] = label_info['name']
            
            result.append({
                "image_id": img['image_id'],
                "filename": img['filename'],
                "annotation": ann
            })
        
        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_result = result[start_idx:end_idx]
        
        return jsonify(paginated_result)
        
    except Exception as e:
        current_app.logger.error(f"è·å–æ•°æ®é›†å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify([])

# è·å–ä¸Šä¸€å¼ å›¾ç‰‡ï¼ˆæ ¹æ®å½“å‰å›¾ç‰‡IDï¼‰
@bp.route('/api/prev_image', methods=['POST'])
def prev_image():
    data = request.json
    ds_id = data.get('dataset_id')
    curr_image_id = data.get('image_id')
    
    try:
        imgs = list(db.images.find({'dataset_id': ds_id}, {'_id': 0}))
        
        # ä¸ºMongoDBä¸­çš„å›¾ç‰‡æ•°æ®æ·»åŠ ç¼ºå¤±çš„image_idå­—æ®µ
        for i, img in enumerate(imgs):
            if 'image_id' not in img:
                img['image_id'] = i + 1  # ç”Ÿæˆä¸€ä¸ªç®€å•çš„image_id
        
        # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®
        if not imgs:
            if isinstance(ds_id, int):
                imgs = [img for img in IMAGES if img['dataset_id'] == ds_id]
            else:
                imgs = []
        
        imgs_sorted = sorted(imgs, key=lambda x: x['image_id'])
        prev_img = None
        for i, img in enumerate(imgs_sorted):
            if img['image_id'] == curr_image_id and i > 0:
                prev_img = imgs_sorted[i-1]
                break
        if prev_img:
            return jsonify(prev_img)
        else:
            return jsonify({"msg": "no previous image"})
            
    except Exception as e:
        current_app.logger.error(f"è·å–ä¸Šä¸€å¼ å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({"msg": "error"})
    
    
@bp.route('/api/labels', methods=['GET'])
def get_labels():
    # è·å–æ ‡ç­¾åˆ—è¡¨æ¥å£ - é‡æ„ä»¥æ”¯æŒæ­£ç¡®çš„æ•°æ®é›†-æ ‡ç­¾å¯¹åº”å…³ç³»
    ds_id = request.args.get('dataset_id')
    
    if not ds_id:
        # å¦‚æœæ²¡æœ‰æä¾›dataset_idï¼Œè¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯æ‰€æœ‰æ ‡ç­¾
        current_app.logger.warning("è·å–æ ‡ç­¾æ—¶æœªæä¾›dataset_idå‚æ•°")
        return jsonify([])
    
    try:
        # å¤„ç†dataset_idï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•´æ•°
        processed_ds_id = ds_id
        if isinstance(ds_id, str) and ds_id.isdigit():
            processed_ds_id = int(ds_id)
        
        # ä½¿ç”¨æ•°æ®é›†ç®¡ç†å™¨è·å–æ ‡ç­¾
        labels_data = dataset_manager.get_dataset_labels(processed_ds_id)
        
        if labels_data:
            current_app.logger.info(f"æˆåŠŸè·å–æ•°æ®é›† {processed_ds_id} çš„æ ‡ç­¾: {len(labels_data)} ä¸ª")
            return jsonify(labels_data)
        else:
            current_app.logger.warning(f"æ•°æ®é›† {processed_ds_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ ‡ç­¾")
            return jsonify([])
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ•°æ®é›† {ds_id} æ ‡ç­¾å¤±è´¥: {e}")
        return jsonify([])

@bp.route('/api/next_image', methods=['POST'])
def next_image():
    # è·å–ä¸‹ä¸€ä¸ªå¾…æ ‡æ³¨å›¾ç‰‡æ¥å£ï¼ˆåŸºäºè§’è‰²çš„ç‹¬ç«‹è¿›åº¦ï¼‰- ä¿®å¤ç‰ˆæœ¬
    data = request.json
    ds_id = data.get('dataset_id')
    expert_id = data.get('expert_id')
    role = data.get('role', 'student')
    
    # æ ¹æ®è§’è‰²ç¡®å®šå®é™…çš„expert_id
    actual_expert_id = ROLE_TO_EXPERT_ID.get(role, 2)
    
    try:
        # å¤„ç†dataset_idï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•´æ•°
        processed_ds_id = ds_id
        if isinstance(ds_id, str) and ds_id.isdigit():
            processed_ds_id = int(ds_id)
        
        # ä½¿ç”¨æ•°æ®é›†ç®¡ç†å™¨è·å–å›¾ç‰‡ä¿¡æ¯
        dataset = dataset_manager.get_dataset_by_id(processed_ds_id)
        if not dataset:
            return jsonify({"msg": "error", "error": f"æ•°æ®é›† {processed_ds_id} æœªæ‰¾åˆ°"})
        
        imgs = dataset['images']
        
        # è·å–è¯¥æ•°æ®é›†ä¸“å±çš„æ ‡æ³¨é›†åˆ
        annotation_collection = get_annotation_collection(processed_ds_id)
        
        # è·å–è¯¥è§’è‰²å·²æ ‡æ³¨çš„å›¾ç‰‡ID
        annotated_imgs = list(annotation_collection.find({
            'expert_id': actual_expert_id
        }, {'_id': 0, 'image_id': 1}))
        
        done_img_ids = set([a['image_id'] for a in annotated_imgs])
        
        current_app.logger.info(f"æ•°æ®é›† {processed_ds_id}ï¼Œè§’è‰² {role}ï¼Œæ€»å›¾ç‰‡ {len(imgs)} å¼ ï¼Œå·²æ ‡æ³¨å›¾ç‰‡ID: {sorted(done_img_ids)}")
        
        # è¿”å›ç¬¬ä¸€ä¸ªæœªæ ‡æ³¨çš„å›¾ç‰‡
        for img in sorted(imgs, key=lambda x: x['image_id']):
            if img['image_id'] not in done_img_ids:
                current_app.logger.info(f"è§’è‰² {role} çš„ä¸‹ä¸€å¼ å›¾ç‰‡: {img['url']} (image_id: {img['image_id']})")
                return jsonify({
                    "image_id": img['image_id'], 
                    "filename": img['filename'],
                    "url": img.get('url', f"/static/{dataset['code']}/{img['filename']}")
                })
        
        # å…¨éƒ¨æ ‡æ³¨å®Œæˆ
        current_app.logger.info(f"è§’è‰² {role} å·²å®Œæˆæ•°æ®é›† {processed_ds_id} çš„æ‰€æœ‰æ ‡æ³¨")
        return jsonify({"msg": "done"})
        
    except Exception as e:
        current_app.logger.error(f"è·å–ä¸‹ä¸€å¼ å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({"msg": "error", "error": str(e)})

def get_annotation_collection(dataset_id):
    """æ ¹æ®æ•°æ®é›†IDè·å–å…¶ä¸“å±çš„MongoDB Collectionå¯¹è±¡"""
    dataset = dataset_manager.get_dataset_by_id(dataset_id)
    if dataset and 'metadata' in dataset and 'annotation_collection' in dataset['metadata']:
        collection_name = dataset['metadata']['annotation_collection']
        return db[collection_name]
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœå…ƒæ•°æ®ä¸­æ²¡æœ‰ï¼Œåˆ™ä½¿ç”¨æ—§çš„å…¨å±€annotationsé›†åˆ
    current_app.logger.warning(f"æ•°æ®é›† {dataset_id} æœªæ‰¾åˆ°ä¸“å±æ ‡æ³¨é›†åˆï¼Œå°†ä½¿ç”¨å…¨å±€ 'annotations' é›†åˆã€‚")
    return db.annotations

@bp.route('/api/annotate', methods=['POST'])
def annotate():
    # æäº¤æ ‡æ³¨ç»“æœæ¥å£ï¼ˆæ”¯æŒåŸºäºè§’è‰²çš„ç‹¬ç«‹æ ‡æ³¨ï¼‰
    data = request.json
    ds_id = data.get('dataset_id')
    image_id = data.get('image_id')
    expert_id = data.get('expert_id')
    label = data.get('label')
    tip = data.get('tip', '')
    
    # å¤„ç†dataset_idï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•´æ•°
    processed_ds_id = ds_id
    if isinstance(ds_id, str) and ds_id.isdigit():
        processed_ds_id = int(ds_id)
    
    # æ ¹æ®ç”¨æˆ·åè·å–è§’è‰²ï¼Œå†ç¡®å®šå®é™…çš„expert_id
    user_role = None
    for user in USERS:
        if user['username'] == expert_id:
            user_role = user['role']
            break
    
    actual_expert_id = ROLE_TO_EXPERT_ID.get(user_role, 2) if user_role else 2
    
    try:
        # è·å–è¯¥æ•°æ®é›†ä¸“å±çš„æ ‡æ³¨é›†åˆ
        annotation_collection = get_annotation_collection(processed_ds_id)

        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¯¥è®°å½•
        existing = annotation_collection.find_one({
            'image_id': image_id,
            'expert_id': actual_expert_id
        })
        
        annotation_data = {
            "dataset_id": processed_ds_id,
            "image_id": image_id,
            "expert_id": actual_expert_id,
            "label_id": label,  # ç»Ÿä¸€ä½¿ç”¨ label_id
            "datetime": datetime.now().isoformat(),
            "tip": tip
        }
        
        if existing:
            # æ›´æ–°ç°æœ‰æ ‡æ³¨ï¼Œä¸éœ€è¦ç”Ÿæˆæ–°çš„record_id
            annotation_data["record_id"] = existing.get("record_id")  # ä¿æŒåŸæœ‰çš„record_id
            
            annotation_collection.update_one(
                {'image_id': image_id, 'expert_id': actual_expert_id},
                {"$set": annotation_data}
            )
            current_app.logger.info(f"æ›´æ–°æ ‡æ³¨: é›†åˆ '{annotation_collection.name}', è§’è‰² {user_role}, å›¾ç‰‡ {image_id}, æ ‡ç­¾ {label}")
        else:
            # æ’å…¥æ–°æ ‡æ³¨ï¼Œä½¿ç”¨è‡ªå¢åºåˆ—ç”Ÿæˆå”¯ä¸€çš„record_id
            try:
                # æ³¨æ„ï¼šget_next_annotation_idç°åœ¨å¯èƒ½éœ€è¦é’ˆå¯¹ä¸åŒé›†åˆè¿›è¡Œç®¡ç†
                # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶ç»§ç»­ä½¿ç”¨å…¨å±€è®¡æ•°å™¨ï¼Œä½†åœ¨å¤§å‹ç³»ç»Ÿä¸­å¯èƒ½éœ€è¦è°ƒæ•´
                next_record_id = get_next_annotation_id(db)
                annotation_data["record_id"] = next_record_id
                
                annotation_collection.insert_one(annotation_data)
                current_app.logger.info(f"æ–°å¢æ ‡æ³¨: é›†åˆ '{annotation_collection.name}', è§’è‰² {user_role}, å›¾ç‰‡ {image_id}, æ ‡ç­¾ {label}, record_id {next_record_id}")
                
            except Exception as insert_error:
                current_app.logger.error(f"ä¿å­˜æ ‡æ³¨åˆ°é›†åˆ '{annotation_collection.name}' å¤±è´¥: {insert_error}")
                return jsonify({"msg": "error", "error": str(insert_error)}), 500
        
        # (å¯é€‰) æ›´æ–°å†…å­˜æ•°æ®ï¼ˆç”¨äºå¤‡ç”¨ï¼‰ï¼Œä½†è¿™éƒ¨åˆ†é€»è¾‘åœ¨å¤šé›†åˆæ¨¡å¼ä¸‹ä¼šå˜å¾—å¤æ‚ä¸”ä¸å‡†ç¡®
        # å»ºè®®æœªæ¥é€æ­¥åºŸå¼ƒå†…å­˜å¤‡ç”¨æ–¹æ¡ˆ
        
        return jsonify({"msg": "saved", "expert_id": actual_expert_id})
        
    except Exception as e:
        current_app.logger.error(f"ä¿å­˜æ ‡æ³¨å¤±è´¥: {e}")
        return jsonify({"msg": "error", "error": str(e)})

@bp.route('/api/update_annotation', methods=['POST'])
def update_annotation():
    # ä¿®æ”¹æ ‡æ³¨æ¥å£ï¼ˆæ”¯æŒåŸºäºè§’è‰²çš„ç‹¬ç«‹æ ‡æ³¨ï¼‰- ä¿®å¤ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¸“å±é›†åˆ
    data = request.json
    ds_id = data.get('dataset_id')
    image_id = data.get('image_id')
    expert_id = data.get('expert_id')
    
    # å¤„ç†dataset_idï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•´æ•°
    processed_ds_id = ds_id
    if isinstance(ds_id, str) and ds_id.isdigit():
        processed_ds_id = int(ds_id)
    
    # æ ¹æ®ç”¨æˆ·åè·å–è§’è‰²
    user_role = None
    for user in USERS:
        if user['username'] == expert_id:
            user_role = user['role']
            break
    
    actual_expert_id = ROLE_TO_EXPERT_ID.get(user_role, 2) if user_role else 2
    
    update_fields = {
        'label_id': data.get('label'),  # ç»Ÿä¸€ä½¿ç”¨label_id
        'tip': data.get('tip', ''),
        'datetime': datetime.now().isoformat()
    }
    
    try:
        # è·å–è¯¥æ•°æ®é›†ä¸“å±çš„æ ‡æ³¨é›†åˆ
        annotation_collection = get_annotation_collection(processed_ds_id)
        
        # æ›´æ–°ä¸“å±é›†åˆä¸­çš„æ•°æ®
        result = annotation_collection.update_one({
            "image_id": image_id, 
            "expert_id": actual_expert_id
        }, {"$set": update_fields})
        
        if result.modified_count > 0:
            current_app.logger.info(f"æ›´æ–°æ ‡æ³¨æˆåŠŸ: é›†åˆ '{annotation_collection.name}', è§’è‰² {user_role}, å›¾ç‰‡ {image_id}")
            return jsonify({"msg": "updated"})
        else:
            return jsonify({"msg": "not found or not changed"})
            
    except Exception as e:
        current_app.logger.error(f"æ›´æ–°æ ‡æ³¨å¤±è´¥: {e}")
        return jsonify({"msg": "error", "error": str(e)})

@bp.route('/api/export', methods=['GET'])
def export():
    # é€šç”¨å¯¼å‡ºæ¥å£ - å¤šå·¥ä½œè¡¨Excelæ–‡ä»¶
    try:
        # è·å–å½“å‰ç”¨æˆ·å’Œæ•°æ®é›†ä¿¡æ¯
        expert_id = request.args.get('expert_id')
        dataset_id = request.args.get('dataset_id')
        
        output = BytesIO()
        current_app.logger.info(f"å¼€å§‹å¯¼å‡ºæ•°æ®ï¼Œexpert_id: {expert_id}, dataset_id: {dataset_id}")
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # 1. å¯¼å‡ºæ ‡æ³¨æ•°æ®è¡¨ (annotations)
            try:
                current_app.logger.info("æ­£åœ¨å¯¼å‡ºæ ‡æ³¨æ•°æ®...")
                annotations_data = list(db.annotations.find({}, {"_id": 0}))
                current_app.logger.info(f"ä»MongoDBè·å–åˆ° {len(annotations_data)} æ¡æ ‡æ³¨æ•°æ®")
                
                if not annotations_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®
                    annotations_data = ANNOTATIONS
                    current_app.logger.info(f"ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®: {len(annotations_data)} æ¡è®°å½•")
                
                if annotations_data:
                    # å¤„ç†å­—æ®µåä¸ä¸€è‡´é—®é¢˜ï¼šç»Ÿä¸€ä½¿ç”¨ label_id
                    for item in annotations_data:
                        if 'label' in item and 'label_id' not in item:
                            item['label_id'] = item['label']
                        item.pop('label', None)  # ç§»é™¤æ—§çš„ label å­—æ®µ
                    
                    # æŒ‰ç…§æ–°çš„å­—æ®µé¡ºåºæ’åˆ—ï¼šdataset_id | record_id | image_id | expert_id | label_id | tip | datetime
                    annotations_df = pd.DataFrame(annotations_data)
                    column_order = ['dataset_id', 'record_id', 'image_id', 'expert_id', 'label_id', 'tip', 'datetime']
                    # åªä¿ç•™å­˜åœ¨çš„åˆ—ï¼Œå¹¶æŒ‰æŒ‡å®šé¡ºåºæ’åˆ—
                    available_columns = [col for col in column_order if col in annotations_df.columns]
                    annotations_df = annotations_df.reindex(columns=available_columns)
                    
                    annotations_df.to_excel(writer, sheet_name='annotations', index=False)
                    current_app.logger.info(f"âœ… æˆåŠŸå¯¼å‡ºæ ‡æ³¨æ•°æ®: {len(annotations_df)} æ¡è®°å½•")
                else:
                    # åˆ›å»ºç©ºçš„æ ‡æ³¨è¡¨ç»“æ„
                    empty_annotations = pd.DataFrame(columns=['dataset_id', 'record_id', 'image_id', 'expert_id', 'label_id', 'tip', 'datetime'])
                    empty_annotations.to_excel(writer, sheet_name='annotations', index=False)
                    current_app.logger.warning("âš ï¸ æ ‡æ³¨æ•°æ®ä¸ºç©ºï¼Œåˆ›å»ºç©ºè¡¨ç»“æ„")
                    
            except Exception as e:
                current_app.logger.error(f"âŒ å¯¼å‡ºæ ‡æ³¨æ•°æ®å¤±è´¥: {e}")
                # åˆ›å»ºé”™è¯¯ä¿¡æ¯è¡¨
                error_df = pd.DataFrame([{'error': f'æ ‡æ³¨æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='annotations', index=False)
            
            # 2. å¯¼å‡ºå›¾ç‰‡æ•°æ®è¡¨ (images)
            try:
                current_app.logger.info("æ­£åœ¨å¯¼å‡ºå›¾ç‰‡æ•°æ®...")
                images_data = list(db.images.find({}, {"_id": 0}))
                current_app.logger.info(f"ä»MongoDBè·å–åˆ° {len(images_data)} æ¡å›¾ç‰‡æ•°æ®")
                
                if not images_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®è½¬æ¢ä¸ºæ–°æ ¼å¼
                    current_app.logger.info("MongoDBä¸­æ— å›¾ç‰‡æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®")
                    images_data = []
                    for img in IMAGES:
                        images_data.append({
                            'image_id': img['image_id'],
                            'image_path': f"static/img/{img['filename']}"
                        })
                    current_app.logger.info(f"å¤‡ç”¨æ•°æ®è½¬æ¢å®Œæˆ: {len(images_data)} æ¡è®°å½•")
                
                if images_data:
                    images_df = pd.DataFrame(images_data)
                    # ç¡®ä¿å­—æ®µé¡ºåºï¼šimage_id | image_path
                    column_order = ['image_id', 'image_path']
                    available_columns = [col for col in column_order if col in images_df.columns]
                    images_df = images_df.reindex(columns=available_columns)
                    
                    images_df.to_excel(writer, sheet_name='images', index=False)
                    current_app.logger.info(f"âœ… æˆåŠŸå¯¼å‡ºå›¾ç‰‡æ•°æ®: {len(images_df)} æ¡è®°å½•")
                else:
                    # åˆ›å»ºç©ºçš„å›¾ç‰‡è¡¨ç»“æ„
                    empty_images = pd.DataFrame(columns=['image_id', 'image_path'])
                    empty_images.to_excel(writer, sheet_name='images', index=False)
                    current_app.logger.warning("âš ï¸ å›¾ç‰‡æ•°æ®ä¸ºç©ºï¼Œåˆ›å»ºç©ºè¡¨ç»“æ„")
                    
            except Exception as e:
                current_app.logger.error(f"âŒ å¯¼å‡ºå›¾ç‰‡æ•°æ®å¤±è´¥: {e}")
                # åˆ›å»ºé”™è¯¯ä¿¡æ¯è¡¨
                error_df = pd.DataFrame([{'error': f'å›¾ç‰‡æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='images', index=False)
            
            # 3. å¯¼å‡ºæ ‡ç­¾æ•°æ®è¡¨ (labels)
            try:
                current_app.logger.info("æ­£åœ¨å¯¼å‡ºæ ‡ç­¾æ•°æ®...")
                labels_data = list(db.labels.find({}, {"_id": 0}))
                current_app.logger.info(f"ä»MongoDBè·å–åˆ° {len(labels_data)} æ¡æ ‡ç­¾æ•°æ®")
                
                if not labels_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®è½¬æ¢ä¸ºæ–°æ ¼å¼
                    current_app.logger.info("MongoDBä¸­æ— æ ‡ç­¾æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®")
                    labels_data = []
                    label_id_set = set()
                    for label in LABELS:
                        if label['label_id'] not in label_id_set:
                            labels_data.append({
                                'label_id': label['label_id'],
                                'label_name': label['name'],
                                'category': 'ç—…ç†å­¦'  # é»˜è®¤åˆ†ç±»
                            })
                            label_id_set.add(label['label_id'])
                    current_app.logger.info(f"å¤‡ç”¨æ•°æ®è½¬æ¢å®Œæˆ: {len(labels_data)} æ¡è®°å½•")
                
                if labels_data:
                    labels_df = pd.DataFrame(labels_data)
                    # ç¡®ä¿å­—æ®µé¡ºåºï¼šlabel_id | label_name | category
                    column_order = ['label_id', 'label_name', 'category']
                    available_columns = [col for col in column_order if col in labels_df.columns]
                    labels_df = labels_df.reindex(columns=available_columns)
                    
                    # æŒ‰label_idæ’åº
                    labels_df = labels_df.sort_values('label_id')
                    
                    labels_df.to_excel(writer, sheet_name='labels', index=False)
                    current_app.logger.info(f"âœ… æˆåŠŸå¯¼å‡ºæ ‡ç­¾æ•°æ®: {len(labels_df)} æ¡è®°å½•")
                else:
                    # åˆ›å»ºç©ºçš„æ ‡ç­¾è¡¨ç»“æ„
                    empty_labels = pd.DataFrame(columns=['label_id', 'label_name', 'category'])
                    empty_labels.to_excel(writer, sheet_name='labels', index=False)
                    current_app.logger.warning("âš ï¸ æ ‡ç­¾æ•°æ®ä¸ºç©ºï¼Œåˆ›å»ºç©ºè¡¨ç»“æ„")
                    
            except Exception as e:
                current_app.logger.error(f"âŒ å¯¼å‡ºæ ‡ç­¾æ•°æ®å¤±è´¥: {e}")
                # åˆ›å»ºé”™è¯¯ä¿¡æ¯è¡¨
                error_df = pd.DataFrame([{'error': f'æ ‡ç­¾æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='labels', index=False)
        
        output.seek(0)
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = "medical_annotation_data"
        if dataset_id:
            filename += f"_dataset_{dataset_id}"
        if expert_id:
            filename += f"_{expert_id}"
        filename += ".xlsx"
        
        current_app.logger.info(f"ğŸ‰ å¯¼å‡ºå®Œæˆï¼Œæ–‡ä»¶å: {filename}")
        
        return send_file(output, 
                        as_attachment=True, 
                        download_name=filename,
                        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    
    except Exception as e:
        current_app.logger.error(f"âŒ é€šç”¨å¯¼å‡ºå¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/export_excel/<string:ds_id>')
def export_excel(ds_id):
    # æ•°æ®é›†ç‰¹å®šå¯¼å‡ºæ¥å£ï¼ˆæ”¯æŒåŸºäºè§’è‰²çš„ç‹¬ç«‹æ•°æ®å¯¼å‡ºï¼‰- å¤šå·¥ä½œè¡¨Excelæ–‡ä»¶
    expert_id = request.args.get('expert_id')
    
    # æ ¹æ®ç”¨æˆ·åè·å–è§’è‰²
    user_role = None
    if expert_id:
        for user in USERS:
            if user['username'] == expert_id:
                user_role = user['role']
                break
    
    actual_expert_id = ROLE_TO_EXPERT_ID.get(user_role, 2) if user_role else 2
    
    try:
        # å¤„ç†dataset_idï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œæ•´æ•°
        processed_ds_id = ds_id
        if isinstance(ds_id, str) and ds_id.isdigit():
            processed_ds_id = int(ds_id)
        
        output = BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # 1. å¯¼å‡ºæ ‡æ³¨æ•°æ®è¡¨ (annotations) - ç­›é€‰ç‰¹å®šæ•°æ®é›†å’Œä¸“å®¶
            try:
                if expert_id:
                    # å¦‚æœæŒ‡å®šäº†ä¸“å®¶ï¼Œåªå¯¼å‡ºè¯¥ä¸“å®¶çš„æ ‡æ³¨
                    query = {"dataset_id": processed_ds_id, "expert_id": actual_expert_id}
                else:
                    # å¦åˆ™å¯¼å‡ºæ•´ä¸ªæ•°æ®é›†çš„æ‰€æœ‰æ ‡æ³¨
                    query = {"dataset_id": processed_ds_id}
                
                annotations_data = list(db.annotations.find(query, {"_id": 0}))
                
                if not annotations_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®
                    if isinstance(processed_ds_id, int):
                        annotations_data = [a for a in ANNOTATIONS if a.get('dataset_id') == processed_ds_id]
                        if expert_id:
                            annotations_data = [a for a in annotations_data if a.get('expert_id') == actual_expert_id]
                    else:
                        annotations_data = []
                
                if annotations_data:
                    # æŒ‰ç…§æ–°çš„å­—æ®µé¡ºåºæ’åˆ—
                    annotations_df = pd.DataFrame(annotations_data)
                    column_order = ['dataset_id', 'record_id', 'image_id', 'expert_id', 'label_id', 'tip', 'datetime']
                    available_columns = [col for col in column_order if col in annotations_df.columns]
                    annotations_df = annotations_df.reindex(columns=available_columns)
                    
                    annotations_df.to_excel(writer, sheet_name='annotations', index=False)
                    current_app.logger.info(f"å¯¼å‡ºæ•°æ®é›†{processed_ds_id}æ ‡æ³¨æ•°æ®: {len(annotations_df)} æ¡è®°å½•")
                else:
                    # åˆ›å»ºç©ºçš„æ ‡æ³¨è¡¨
                    empty_annotations = pd.DataFrame(columns=['dataset_id', 'record_id', 'image_id', 'expert_id', 'label_id', 'tip', 'datetime'])
                    empty_annotations.to_excel(writer, sheet_name='annotations', index=False)
                    current_app.logger.warning(f"æ•°æ®é›†{processed_ds_id}æ— æ ‡æ³¨æ•°æ®")
                    
            except Exception as e:
                current_app.logger.error(f"å¯¼å‡ºæ•°æ®é›†{processed_ds_id}æ ‡æ³¨æ•°æ®å¤±è´¥: {e}")
                error_df = pd.DataFrame([{'error': f'æ ‡æ³¨æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='annotations', index=False)
            
            # 2. å¯¼å‡ºè¯¥æ•°æ®é›†ç›¸å…³çš„å›¾ç‰‡æ•°æ®è¡¨ (images)
            try:
                # é€šè¿‡å…³è”è¡¨æŸ¥è¯¢è¯¥æ•°æ®é›†çš„å›¾ç‰‡
                dataset_images = list(db.image_datasets.find({"dataset_id": processed_ds_id}, {"_id": 0, "image_id": 1}))
                image_ids = [img['image_id'] for img in dataset_images]
                
                if image_ids:
                    # è·å–å›¾ç‰‡è¯¦ç»†ä¿¡æ¯
                    images_data = list(db.images.find({"image_id": {"$in": image_ids}}, {"_id": 0}))
                else:
                    images_data = []
                
                if not images_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®
                    if isinstance(processed_ds_id, int):
                        backup_images = [img for img in IMAGES if img.get('dataset_id') == processed_ds_id]
                        images_data = []
                        for img in backup_images:
                            images_data.append({
                                'image_id': img['image_id'],
                                'image_path': f"static/img/{img['filename']}"
                            })
                
                if images_data:
                    images_df = pd.DataFrame(images_data)
                    column_order = ['image_id', 'image_path']
                    available_columns = [col for col in column_order if col in images_df.columns]
                    images_df = images_df.reindex(columns=available_columns)
                    
                    images_df.to_excel(writer, sheet_name='images', index=False)
                    current_app.logger.info(f"å¯¼å‡ºæ•°æ®é›†{processed_ds_id}å›¾ç‰‡æ•°æ®: {len(images_df)} æ¡è®°å½•")
                else:
                    empty_images = pd.DataFrame(columns=['image_id', 'image_path'])
                    empty_images.to_excel(writer, sheet_name='images', index=False)
                    
            except Exception as e:
                current_app.logger.error(f"å¯¼å‡ºæ•°æ®é›†{processed_ds_id}å›¾ç‰‡æ•°æ®å¤±è´¥: {e}")
                error_df = pd.DataFrame([{'error': f'å›¾ç‰‡æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='images', index=False)
            
            # 3. å¯¼å‡ºæ ‡ç­¾æ•°æ®è¡¨ (labels) - å¯¼å‡ºæ‰€æœ‰æ ‡ç­¾ä¾›å‚è€ƒ
            try:
                labels_data = list(db.labels.find({}, {"_id": 0}))
                if not labels_data:
                    # ä½¿ç”¨å¤‡ç”¨å†…å­˜æ•°æ®è½¬æ¢ä¸ºæ–°æ ¼å¼
                    labels_data = []
                    if isinstance(processed_ds_id, int):
                        backup_labels = [l for l in LABELS if l.get('dataset_id') == processed_ds_id]
                        for label in backup_labels:
                            labels_data.append({
                                'label_id': label['label_id'],
                                'label_name': label['name'],
                                'category': 'ç—…ç†å­¦'  # é»˜è®¤åˆ†ç±»
                            })
                    
                    # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æ‰€æœ‰LABELSä½œä¸ºå¤‡ç”¨
                    if not labels_data:
                        label_id_set = set()
                        for label in LABELS:
                            if label['label_id'] not in label_id_set:
                                labels_data.append({
                                    'label_id': label['label_id'],
                                    'label_name': label['name'],
                                    'category': 'ç—…ç†å­¦'
                                })
                                label_id_set.add(label['label_id'])
                
                if labels_data:
                    labels_df = pd.DataFrame(labels_data)
                    column_order = ['label_id', 'label_name', 'category']
                    available_columns = [col for col in column_order if col in labels_df.columns]
                    labels_df = labels_df.reindex(columns=available_columns)
                    
                    # æŒ‰label_idæ’åº
                    labels_df = labels_df.sort_values('label_id')
                    
                    labels_df.to_excel(writer, sheet_name='labels', index=False)
                    current_app.logger.info(f"å¯¼å‡ºæ ‡ç­¾æ•°æ®: {len(labels_df)} æ¡è®°å½•")
                else:
                    empty_labels = pd.DataFrame(columns=['label_id', 'label_name', 'category'])
                    empty_labels.to_excel(writer, sheet_name='labels', index=False)
                    
            except Exception as e:
                current_app.logger.error(f"å¯¼å‡ºæ ‡ç­¾æ•°æ®å¤±è´¥: {e}")
                error_df = pd.DataFrame([{'error': f'æ ‡ç­¾æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}'}])
                error_df.to_excel(writer, sheet_name='labels', index=False)
        
        output.seek(0)
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"dataset_{processed_ds_id}_medical_data"
        if expert_id:
            filename += f"_{user_role}_role"
        filename += ".xlsx"
        
        return send_file(output, 
                        as_attachment=True, 
                        download_name=filename, 
                        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    
    except Exception as e:
        current_app.logger.error(f"æ•°æ®é›†{ds_id}å¯¼å‡ºExcelå¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/export_dataset', methods=['GET'])
def export_dataset():
    """å¯¼å‡ºå•ä¸ªæ•°æ®é›†çš„Excelæ–‡ä»¶ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¸“å±æ ‡æ³¨é›†åˆï¼‰"""
    dataset_id = request.args.get('dataset_id')
    
    if not dataset_id:
        return jsonify({"error": "ç¼ºå°‘dataset_idå‚æ•°"}), 400
    
    try:
        dataset_id = int(dataset_id)
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        dataset = dataset_manager.get_dataset_by_id(dataset_id)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {dataset_id} æœªæ‰¾åˆ°"}), 404
        
        # è·å–è¯¥æ•°æ®é›†ä¸“å±çš„æ ‡æ³¨é›†åˆ
        annotation_collection = get_annotation_collection(dataset_id)
        
        # ä»ä¸“å±é›†åˆä¸­è·å–æ‰€æœ‰æ ‡æ³¨æ•°æ®
        annotations_data = list(annotation_collection.find({}, {"_id": 0}))
        current_app.logger.info(f"ä»é›†åˆ '{annotation_collection.name}' è·å–åˆ° {len(annotations_data)} æ¡æ ‡æ³¨æ•°æ®")
        
        # è·å–æ ‡ç­¾æ˜ å°„
        labels_map = {}
        dataset_labels = dataset_manager.get_dataset_labels(dataset_id)
        for label in dataset_labels:
            labels_map[label.get('label_id')] = label.get('name', 'æœªçŸ¥æ ‡ç­¾')
        
        # åˆ›å»ºå¯¼å‡ºæ•°æ®
        export_data = []
        for image in dataset['images']:
            # æŸ¥æ‰¾è¯¥å›¾ç‰‡çš„æ ‡æ³¨
            image_annotations = [a for a in annotations_data if a['image_id'] == image['image_id']]
            
            if image_annotations:
                # æœ‰æ ‡æ³¨çš„å›¾ç‰‡
                for annotation in image_annotations:
                    label_name = labels_map.get(annotation.get('label_id'), 'æœªçŸ¥æ ‡ç­¾')
                    export_record = {
                        'dataset_id': dataset_id,
                        'dataset_code': dataset['code'],
                        'dataset_name': dataset['name'],
                        'image_id': image['image_id'],
                        'display_id': image.get('display_id', ''),
                        'seq_in_dataset': image.get('seq_in_dataset', 0),
                        'filename': image['filename'],
                        'label_id': annotation.get('label_id'),
                        'label_name': label_name,
                        'tip': annotation.get('tip', ''),
                        'expert_id': annotation.get('expert_id'),
                        'annotated_at': annotation.get('datetime', ''),
                        'created_at': image.get('created_at', ''),
                        'file_size': image.get('file_size', 0)
                    }
                    export_data.append(export_record)
            else:
                # æœªæ ‡æ³¨çš„å›¾ç‰‡
                export_record = {
                    'dataset_id': dataset_id,
                    'dataset_code': dataset['code'],
                    'dataset_name': dataset['name'],
                    'image_id': image['image_id'],
                    'display_id': image.get('display_id', ''),
                    'seq_in_dataset': image.get('seq_in_dataset', 0),
                    'filename': image['filename'],
                    'label_id': None,
                    'label_name': 'æœªæ ‡æ³¨',
                    'tip': '',
                    'expert_id': None,
                    'annotated_at': '',
                    'created_at': image.get('created_at', ''),
                    'file_size': image.get('file_size', 0)
                }
                export_data.append(export_record)
        
        if not export_data:
            return jsonify({"error": f"æ•°æ®é›† {dataset_id} æ— æ•°æ®å¯å¯¼å‡º"}), 404
        
        # åˆ›å»ºExcelæ–‡ä»¶
        output = BytesIO()
        df = pd.DataFrame(export_data)
        
        # å­—æ®µæ’åº
        column_order = [
            'dataset_id', 'dataset_code', 'dataset_name',
            'image_id', 'display_id', 'seq_in_dataset', 'filename',
            'label_id', 'label_name', 'tip',
            'expert_id', 'annotated_at', 'created_at', 'file_size'
        ]
        available_columns = [col for col in column_order if col in df.columns]
        df = df.reindex(columns=available_columns)
        
        # æŒ‰seq_in_datasetæ’åº
        df = df.sort_values('seq_in_dataset')
        
        # å†™å…¥Excel
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='dataset_annotations', index=False)
        
        output.seek(0)
        
        # ç”Ÿæˆæ–‡ä»¶å
        dataset_code = dataset['code']
        filename = f"{dataset_code}_annotations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        current_app.logger.info(f"æˆåŠŸå¯¼å‡ºæ•°æ®é›† {dataset_id} (é›†åˆ: {annotation_collection.name})ï¼Œå…± {len(export_data)} æ¡è®°å½•")
        
        return send_file(output, 
                        as_attachment=True, 
                        download_name=filename, 
                        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    
    except Exception as e:
        current_app.logger.error(f"å¯¼å‡ºæ•°æ®é›† {dataset_id} å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/export_all', methods=['GET'])
def export_all_datasets():
    """å¯¼å‡ºæ‰€æœ‰æ•°æ®é›†çš„Excelæ–‡ä»¶ï¼ˆå¤šSheetæ ¼å¼ï¼‰"""
    try:
        # ä½¿ç”¨æ•°æ®é›†ç®¡ç†å™¨è·å–æ‰€æœ‰æ•°æ®é›†çš„å¯¼å‡ºæ•°æ®
        all_export_data = dataset_manager.get_export_data()
        
        if not all_export_data:
            return jsonify({"error": "æœªæ‰¾åˆ°ä»»ä½•æ•°æ®é›†æˆ–æ•°æ®"}), 404
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„
        datasets_data = {}
        for record in all_export_data:
            dataset_code = record['dataset_code']
            if dataset_code not in datasets_data:
                datasets_data[dataset_code] = []
            datasets_data[dataset_code].append(record)
        
        # åˆ›å»ºExcelæ–‡ä»¶
        output = BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºä¸€ä¸ªSheet
            for dataset_code, data in datasets_data.items():
                df = pd.DataFrame(data)
                
                # å­—æ®µæ’åº
                column_order = [
                    'dataset_id', 'dataset_code', 'dataset_name',
                    'image_id', 'display_id', 'seq_in_dataset', 'filename',
                    'label_id', 'label_name', 'tip',
                    'expert_id', 'annotated_at', 'created_at', 'file_size'
                ]
                available_columns = [col for col in column_order if col in df.columns]
                df = df.reindex(columns=available_columns)
                
                # æŒ‰seq_in_datasetæ’åº
                df = df.sort_values('seq_in_dataset')
                
                # ä½¿ç”¨æ•°æ®é›†ä»£ç ä½œä¸ºSheetåç§°ï¼ˆExcel Sheetåç§°é™åˆ¶31å­—ç¬¦ï¼‰
                sheet_name = dataset_code[:31] if len(dataset_code) > 31 else dataset_code
                df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # åˆ›å»ºæ±‡æ€»Sheet
            all_df = pd.DataFrame(all_export_data)
            column_order = [
                'dataset_id', 'dataset_code', 'dataset_name',
                'image_id', 'display_id', 'seq_in_dataset', 'filename',
                'label_id', 'label_name', 'tip',
                'expert_id', 'annotated_at', 'created_at', 'file_size'
            ]
            available_columns = [col for col in column_order if col in all_df.columns]
            all_df = all_df.reindex(columns=available_columns)
            all_df = all_df.sort_values(['dataset_id', 'seq_in_dataset'])
            all_df.to_excel(writer, sheet_name='All_Datasets', index=False)
        
        output.seek(0)
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"all_datasets_annotations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        total_records = len(all_export_data)
        total_datasets = len(datasets_data)
        current_app.logger.info(f"æˆåŠŸå¯¼å‡ºæ‰€æœ‰æ•°æ®é›†ï¼Œå…± {total_datasets} ä¸ªæ•°æ®é›†ï¼Œ{total_records} æ¡è®°å½•")
        
        return send_file(output, 
                        as_attachment=True, 
                        download_name=filename, 
                        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    
    except Exception as e:
        current_app.logger.error(f"å¯¼å‡ºæ‰€æœ‰æ•°æ®é›†å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/datasets/scan', methods=['POST'])
def scan_datasets():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é›†æ‰«æ"""
    try:
        # å¼ºåˆ¶åˆ·æ–°æ•°æ®é›†ç¼“å­˜
        datasets = dataset_manager.scan_datasets(force_refresh=True)
        
        return jsonify({
            "message": "æ•°æ®é›†æ‰«æå®Œæˆ",
            "datasets_count": len(datasets),
            "datasets": list(datasets.keys())
        })
    
    except Exception as e:
        current_app.logger.error(f"æ‰«ææ•°æ®é›†å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/datasets/<int:dataset_id>/info', methods=['GET'])
def get_dataset_info(dataset_id):
    """è·å–æ•°æ®é›†è¯¦ç»†ä¿¡æ¯"""
    try:
        dataset = dataset_manager.get_dataset_by_id(dataset_id)
        
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {dataset_id} ä¸å­˜åœ¨"}), 404
        
        # è¿”å›æ•°æ®é›†ä¿¡æ¯ï¼ˆä¸åŒ…å«å®Œæ•´çš„å›¾ç‰‡åˆ—è¡¨ä»¥å‡å°‘å“åº”å¤§å°ï¼‰
        info = {
            'id': dataset['id'],
            'code': dataset['code'],
            'name': dataset['name'],
            'description': dataset['description'],
            'category': dataset.get('category', 'general'),
            'total_images': dataset['total_images'],
            'active': dataset.get('active', True),
            'created_at': dataset.get('created_at'),
            'folder_path': dataset['folder_path'],
            'metadata': dataset.get('metadata', {})
        }
        
        return jsonify(info)
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# ============= Adminæ•°æ®é›†ç®¡ç†æ¥å£ =============

def check_admin_auth(expert_id):
    """æ£€æŸ¥æ˜¯å¦ä¸ºadminç”¨æˆ·"""
    if not expert_id:
        return False
    for user in USERS:
        if user['username'] == expert_id and user['role'] == 'admin':
            return True
    return False

@bp.route('/api/admin/datasets', methods=['GET'])
def admin_get_all_datasets():
    """ç®¡ç†å‘˜è·å–æ‰€æœ‰æ•°æ®é›†ï¼ˆåŒ…æ‹¬æœªæ¿€æ´»çš„ï¼‰"""
    expert_id = request.args.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        # å¼ºåˆ¶åˆ·æ–°å¹¶è·å–æ‰€æœ‰æ•°æ®é›†
        datasets = dataset_manager.scan_datasets(force_refresh=True)
        
        # è¿”å›å®Œæ•´ä¿¡æ¯
        result = []
        for code, dataset in datasets.items():
            result.append({
                'id': dataset['id'],
                'code': dataset['code'],
                'name': dataset['name'],
                'description': dataset['description'],
                'category': dataset.get('category', 'general'),
                'total_images': dataset['total_images'],
                'active': dataset.get('active', True),
                'created_at': dataset.get('created_at'),
                'folder_path': dataset['folder_path'],
                'metadata': dataset.get('metadata', {})
            })
        
        current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} æŸ¥çœ‹æ‰€æœ‰æ•°æ®é›†ï¼Œå…± {len(result)} ä¸ª")
        return jsonify(result)
    
    except Exception as e:
        current_app.logger.error(f"ç®¡ç†å‘˜è·å–æ•°æ®é›†å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/admin/datasets/<string:code>/toggle', methods=['POST'])
def admin_toggle_dataset(code):
    """ç®¡ç†å‘˜åˆ‡æ¢æ•°æ®é›†æ¿€æ´»çŠ¶æ€"""
    data = request.json
    expert_id = data.get('expert_id')
    active = data.get('active', True)
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        dataset = dataset_manager.get_dataset_by_code(code)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {code} ä¸å­˜åœ¨"}), 404
        
        # æ›´æ–°å…ƒæ•°æ®
        metadata = dataset.get('metadata', {})
        metadata['active'] = active
        metadata['last_modified'] = datetime.now().isoformat()
        metadata['modified_by'] = expert_id
        
        success = dataset_manager.create_dataset_metadata(code, metadata)
        
        if success:
            action = "æ¿€æ´»" if active else "åœç”¨"
            current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} {action}æ•°æ®é›† {code}")
            return jsonify({"message": f"æ•°æ®é›† {code} å·²{action}"})
        else:
            return jsonify({"error": "æ›´æ–°å¤±è´¥"}), 500
    
    except Exception as e:
        current_app.logger.error(f"åˆ‡æ¢æ•°æ®é›†çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/admin/datasets/<string:code>/metadata', methods=['PUT'])
def admin_update_dataset_metadata(code):
    """ç®¡ç†å‘˜æ›´æ–°æ•°æ®é›†å…ƒæ•°æ®"""
    data = request.json
    expert_id = data.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        dataset = dataset_manager.get_dataset_by_code(code)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {code} ä¸å­˜åœ¨"}), 404
        
        # æ›´æ–°å…ƒæ•°æ®
        metadata = dataset.get('metadata', {})
        
        # å…è®¸æ›´æ–°çš„å­—æ®µ
        updatable_fields = ['name', 'description', 'category']
        for field in updatable_fields:
            if field in data:
                metadata[field] = data[field]
        
        metadata['last_modified'] = datetime.now().isoformat()
        metadata['modified_by'] = expert_id
        
        success = dataset_manager.create_dataset_metadata(code, metadata)
        
        if success:
            current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} æ›´æ–°æ•°æ®é›† {code} å…ƒæ•°æ®")
            return jsonify({"message": f"æ•°æ®é›† {code} å…ƒæ•°æ®å·²æ›´æ–°"})
        else:
            return jsonify({"error": "æ›´æ–°å¤±è´¥"}), 500
    
    except Exception as e:
        current_app.logger.error(f"æ›´æ–°æ•°æ®é›†å…ƒæ•°æ®å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/admin/datasets/create', methods=['POST'])
def admin_create_dataset():
    """
    ç®¡ç†å‘˜åˆ›å»ºæ–°æ•°æ®é›†ã€‚
    æ­¤æ“ä½œä¼šåˆ›å»ºæ–‡ä»¶ç›®å½•ã€å…ƒæ•°æ®æ–‡ä»¶ï¼Œå¹¶åœ¨æ•°æ®åº“ä¸­åˆ›å»ºä¸“å±çš„æ ‡æ³¨é›†åˆã€‚
    å¢åŠ äº†å¯¹å­¤å„¿æ•°æ®åº“é›†åˆçš„è‡ªåŠ¨æ¸…ç†åŠŸèƒ½ã€‚
    """
    data = request.json
    expert_id = data.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        code = data.get('code', '').strip()
        name = data.get('name', '').strip()
        description = data.get('description', '').strip()
        category = data.get('category', 'general').strip()
        labels = data.get('labels', [])
        
        if not code or not name:
            return jsonify({"error": "æ•°æ®é›†ä»£ç å’Œåç§°ä¸èƒ½ä¸ºç©º"}), 400
        
        if not labels or not isinstance(labels, list):
            return jsonify({"error": "å¿…é¡»æä¾›è‡³å°‘ä¸€ä¸ªæ ‡ç­¾"}), 400
        
        for i, label in enumerate(labels):
            if not isinstance(label, dict) or not label.get('name', '').strip():
                return jsonify({"error": f"æ ‡ç­¾ {i+1} æ ¼å¼é”™è¯¯æˆ–åç§°ä¸ºç©º"}), 400
        
        dataset_path = os.path.join(dataset_manager.static_root, code)
        metadata_path = os.path.join(dataset_path, dataset_manager.metadata_filename)
        collection_name = f"annotations_{code}"

        # --- å¢å¼ºçš„é¢„æ£€æŸ¥å’Œè‡ªæ„ˆé€»è¾‘ ---
        collection_exists = collection_name in db.list_collection_names()
        metadata_exists = os.path.exists(metadata_path)

        if dataset_manager.get_dataset_by_code(code) and metadata_exists:
            return jsonify({"error": f"æ•°æ®é›†ä»£ç  {code} å·²å®Œå…¨å­˜åœ¨"}), 400

        if collection_exists and not metadata_exists:
            # å‘ç°å­¤å„¿é›†åˆï¼Œè‡ªåŠ¨æ¸…ç†
            db.drop_collection(collection_name)
            current_app.logger.warning(f"å‘ç°å¹¶å·²è‡ªåŠ¨åˆ é™¤å­¤å„¿æ•°æ®åº“é›†åˆ: {collection_name}")

        # --- äº‹åŠ¡æ€§æ“ä½œå¼€å§‹ ---
        if not os.path.exists(dataset_path):
            os.makedirs(dataset_path, exist_ok=True)
        
        metadata = {
            'name': name,
            'description': description,
            'category': category,
            'active': True,
            'created_at': datetime.now().isoformat(),
            'created_by': expert_id,
            'annotation_collection': collection_name
        }
        
        if not dataset_manager.create_dataset_metadata(code, metadata):
            return jsonify({"error": "åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶å¤±è´¥"}), 500

        try:
            collection = db.create_collection(collection_name)
            collection.create_index(
                [("image_id", 1), ("expert_id", 1)], 
                unique=True,
                name="image_expert_compound_idx"
            )
            current_app.logger.info(f"æˆåŠŸåˆ›å»ºæ•°æ®åº“é›†åˆ '{collection_name}' å¹¶è®¾ç½®ç´¢å¼•ã€‚")
        except Exception as db_error:
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
            if not os.listdir(dataset_path):
                os.rmdir(dataset_path)
            current_app.logger.error(f"åˆ›å»ºæ•°æ®åº“é›†åˆå¤±è´¥ï¼Œå·²å›æ»šæ–‡ä»¶æ“ä½œ: {db_error}")
            return jsonify({"error": f"æ•°æ®åº“æ“ä½œå¤±è´¥: {db_error}"}), 500

        new_dataset = dataset_manager.get_dataset_by_code(code)
        if not new_dataset:
            return jsonify({"error": "æ•°æ®é›†åˆ›å»ºåæ— æ³•åœ¨ç¼“å­˜ä¸­æ‰¾åˆ°"}), 500
            
        dataset_id = new_dataset['id']
        
        if not dataset_manager.create_dataset_labels(dataset_id, labels):
            current_app.logger.warning(f"æ•°æ®é›† {code} å·²åˆ›å»ºï¼Œä½†æ ‡ç­¾åˆ›å»ºå¤±è´¥ã€‚")
            return jsonify({
                "message": f"æ•°æ®é›† {code} å’Œæ•°æ®åº“é›†åˆåˆ›å»ºæˆåŠŸï¼Œä½†æ ‡ç­¾åˆ›å»ºå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ·»åŠ ã€‚",
                "dataset_id": dataset_id,
                "collection_created": collection_name
            }), 201

        current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} æˆåŠŸåˆ›å»ºæ•°æ®é›† {code} (ID: {dataset_id})ï¼ŒåŒ…å« {len(labels)} ä¸ªæ ‡ç­¾å’Œæ•°æ®åº“é›†åˆ '{collection_name}'")
        return jsonify({
            "message": f"æ•°æ®é›† {code}ã€æ ‡ç­¾å’Œæ•°æ®åº“é›†åˆå·²å…¨éƒ¨æˆåŠŸåˆ›å»ºï¼",
            "dataset_id": dataset_id,
            "collection_created": collection_name,
            "labels_created": len(labels)
        }), 201

    except Exception as e:
        current_app.logger.error(f"åˆ›å»ºæ•°æ®é›†çš„æœªçŸ¥é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500

# ============= æ–‡ä»¶ä¸Šä¼ ç®¡ç†æ¥å£ =============

@bp.route('/api/admin/datasets/<string:code>/upload', methods=['POST'])
def admin_upload_images(code):
    """ç®¡ç†å‘˜ä¸Šä¼ å›¾ç‰‡åˆ°æŒ‡å®šæ•°æ®é›†"""
    expert_id = request.form.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        dataset = dataset_manager.get_dataset_by_code(code)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {code} ä¸å­˜åœ¨"}), 404
        
        if 'files' not in request.files:
            return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400
        
        files = request.files.getlist('files')
        if not files or files[0].filename == '':
            return jsonify({"error": "æœªé€‰æ‹©æœ‰æ•ˆæ–‡ä»¶"}), 400
        
        uploaded_files = []
        failed_files = []
        
        for file in files:
            if file and file.filename:
                # æ£€æŸ¥æ–‡ä»¶ç±»å‹
                filename = file.filename
                _, ext = os.path.splitext(filename.lower())
                
                if ext not in dataset_manager.image_extensions:
                    failed_files.append(f"{filename}: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                    continue
                
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                import uuid
                safe_filename = f"{uuid.uuid4().hex}_{filename}"
                
                # ä¿å­˜æ–‡ä»¶
                file_path = os.path.join(dataset['folder_path'], safe_filename)
                try:
                    file.save(file_path)
                    uploaded_files.append(safe_filename)
                    current_app.logger.info(f"ä¸Šä¼ å›¾ç‰‡: {safe_filename} åˆ°æ•°æ®é›† {code}")
                except Exception as save_error:
                    failed_files.append(f"{filename}: ä¿å­˜å¤±è´¥ - {str(save_error)}")
        
        # åˆ·æ–°æ•°æ®é›†ç¼“å­˜
        dataset_manager.scan_datasets(force_refresh=True)
        
        result = {
            "message": f"ä¸Šä¼ å®Œæˆ",
            "uploaded": len(uploaded_files),
            "failed": len(failed_files),
            "uploaded_files": uploaded_files,
            "failed_files": failed_files
        }
        
        current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} å‘æ•°æ®é›† {code} ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        return jsonify(result)
    
    except Exception as e:
        current_app.logger.error(f"ä¸Šä¼ å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/admin/datasets/<string:code>/images', methods=['GET'])
def admin_get_dataset_images(code):
    """ç®¡ç†å‘˜è·å–æ•°æ®é›†å›¾ç‰‡åˆ—è¡¨"""
    expert_id = request.args.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        dataset = dataset_manager.get_dataset_by_code(code)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {code} ä¸å­˜åœ¨"}), 404
        
        images = dataset['images']
        
        # æ·»åŠ å›¾ç‰‡é¢„è§ˆURL
        for img in images:
            img['preview_url'] = f"/static/{code}/{img['filename']}"
        
        return jsonify({
            "dataset_code": code,
            "dataset_name": dataset['name'],
            "total_images": len(images),
            "images": images
        })
    
    except Exception as e:
        current_app.logger.error(f"è·å–æ•°æ®é›†å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

@bp.route('/api/admin/datasets/<string:code>/images/<string:filename>', methods=['DELETE'])
def admin_delete_image(code, filename):
    """ç®¡ç†å‘˜åˆ é™¤æ•°æ®é›†ä¸­çš„å›¾ç‰‡"""
    data = request.json
    expert_id = data.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        dataset = dataset_manager.get_dataset_by_code(code)
        if not dataset:
            return jsonify({"error": f"æ•°æ®é›† {code} ä¸å­˜åœ¨"}), 404
        
        file_path = os.path.join(dataset['folder_path'], filename)
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æ–‡ä»¶ {filename} ä¸å­˜åœ¨"}), 404
        
        # åˆ é™¤æ–‡ä»¶
        os.remove(file_path)
        
        # åˆ·æ–°æ•°æ®é›†ç¼“å­˜
        dataset_manager.scan_datasets(force_refresh=True)
        
        current_app.logger.info(f"ç®¡ç†å‘˜ {expert_id} åˆ é™¤æ•°æ®é›† {code} ä¸­çš„å›¾ç‰‡ {filename}")
        return jsonify({"message": f"å›¾ç‰‡ {filename} å·²åˆ é™¤"})
    
    except Exception as e:
        current_app.logger.error(f"åˆ é™¤å›¾ç‰‡å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# ============= æ•°æ®é›†ç»Ÿè®¡æ¥å£ =============

@bp.route('/api/admin/statistics', methods=['GET'])
def admin_get_statistics():
    """ç®¡ç†å‘˜è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    expert_id = request.args.get('expert_id')
    
    if not check_admin_auth(expert_id):
        return jsonify({"error": "æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®"}), 403
    
    try:
        datasets = dataset_manager.scan_datasets(force_refresh=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_datasets = len(datasets)
        active_datasets = sum(1 for ds in datasets.values() if ds.get('active', True))
        total_images = sum(ds['total_images'] for ds in datasets.values())
        
        # æ ‡æ³¨ç»Ÿè®¡
        total_annotations = 0
        annotations_by_role = {'admin': 0, 'doctor': 0, 'student': 0}
        
        try:
            # ä»MongoDBè·å–æ ‡æ³¨ç»Ÿè®¡
            annotations = list(db.annotations.find({}, {'_id': 0, 'expert_id': 1}))
            if not annotations:
                annotations = ANNOTATIONS
            
            total_annotations = len(annotations)
            
            for ann in annotations:
                expert_id_val = ann.get('expert_id', 2)
                role_name = None
                for role, role_id in ROLE_TO_EXPERT_ID.items():
                    if role_id == expert_id_val:
                        role_name = role
                        break
                
                if role_name and role_name in annotations_by_role:
                    annotations_by_role[role_name] += 1
        
        except Exception as e:
            current_app.logger.warning(f"è·å–æ ‡æ³¨ç»Ÿè®¡å¤±è´¥: {e}")
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„çš„ç»Ÿè®¡
        dataset_stats = []
        for code, dataset in datasets.items():
            ds_annotations = 0
            try:
                ds_annotations = len(list(db.annotations.find({'dataset_id': dataset['id']}, {'_id': 0})))
                if ds_annotations == 0:
                    ds_annotations = len([a for a in ANNOTATIONS if a.get('dataset_id') == dataset['id']])
            except:
                ds_annotations = len([a for a in ANNOTATIONS if a.get('dataset_id') == dataset['id']])
            
            dataset_stats.append({
                'code': code,
                'name': dataset['name'],
                'total_images': dataset['total_images'],
                'total_annotations': ds_annotations,
                'completion_rate': round((ds_annotations / dataset['total_images'] * 100) if dataset['total_images'] > 0 else 0, 2),
                'active': dataset.get('active', True)
            })
        
        result = {
            'system_overview': {
                'total_datasets': total_datasets,
                'active_datasets': active_datasets,
                'total_images': total_images,
                'total_annotations': total_annotations
            },
            'annotations_by_role': annotations_by_role,
            'dataset_statistics': dataset_stats,
            'generated_at': datetime.now().isoformat()
        }
        
        return jsonify(result)
    
    except Exception as e:
        current_app.logger.error(f"è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({"error": str(e)}), 500

# ============= Webç®¡ç†ç•Œé¢ =============

@bp.route('/admin')
def admin_page():
    """ç®¡ç†å‘˜Webç•Œé¢"""
    return render_template('admin.html')

@bp.route('/admin/datasets')
def admin_datasets_page():
    """æ•°æ®é›†ç®¡ç†é¡µé¢"""
    return render_template('admin.html')

# =========================
# æ ‡ç­¾ç®¡ç† API
# =========================

@bp.route('/api/admin/labels/<int:dataset_id>', methods=['GET'])
def get_dataset_labels(dataset_id):
    """è·å–æ•°æ®é›†çš„æ ‡ç­¾åˆ—è¡¨"""
    try:
        labels = dataset_manager.get_dataset_labels(dataset_id)
        return jsonify({"success": True, "labels": labels})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@bp.route('/api/admin/labels', methods=['POST'])
def create_label():
    """åˆ›å»ºæ–°æ ‡ç­¾"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "error": "ç¼ºå°‘æ•°æ®"}), 400
        
        required_fields = ['dataset_id', 'name']
        for field in required_fields:
            if field not in data:
                return jsonify({"success": False, "error": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}), 400
        
        dataset_id = data['dataset_id']
        name = data['name'].strip()
        description = data.get('description', '').strip()
        
        if not name:
            return jsonify({"success": False, "error": "æ ‡ç­¾åç§°ä¸èƒ½ä¸ºç©º"}), 400
        
        # æ£€æŸ¥æ ‡ç­¾åæ˜¯å¦å·²å­˜åœ¨
        existing_labels = dataset_manager.get_dataset_labels(dataset_id)
        if any(label['name'] == name for label in existing_labels):
            return jsonify({"success": False, "error": "æ ‡ç­¾åç§°å·²å­˜åœ¨"}), 400
        
        # è®¡ç®—æ–°çš„label_id
        max_id = max([label.get('label_id', 0) for label in existing_labels]) if existing_labels else 0
        new_label_id = max_id + 1
        
        # åˆ›å»ºæ ‡ç­¾æ–‡æ¡£
        label_doc = {
            "label_id": new_label_id,
            "dataset_id": dataset_id,
            "name": name,
            "description": description,
            "active": True,
            "created_at": datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            db.labels.insert_one(label_doc.copy())
        except Exception as e:
            logger.warning(f"MongoDBä¿å­˜æ ‡ç­¾å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨: {e}")
        
        # ä¿å­˜åˆ°å†…å­˜ç»“æ„
        memory_label = {
            "label_id": new_label_id,
            "dataset_id": dataset_id,
            "name": name
        }
        LABELS.append(memory_label)
        
        return jsonify({"success": True, "label": label_doc})
        
    except Exception as e:
        logger.error(f"åˆ›å»ºæ ‡ç­¾å¤±è´¥: {e}")
        return jsonify({"success": False, "error": "åˆ›å»ºæ ‡ç­¾å¤±è´¥"}), 500

@bp.route('/api/admin/labels/<int:label_id>', methods=['PUT'])
def update_label(label_id):
    """æ›´æ–°æ ‡ç­¾"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "error": "ç¼ºå°‘æ•°æ®"}), 400
        
        name = data.get('name', '').strip()
        description = data.get('description', '').strip()
        
        if not name:
            return jsonify({"success": False, "error": "æ ‡ç­¾åç§°ä¸èƒ½ä¸ºç©º"}), 400
        
        # æ›´æ–°æ•°æ®åº“
        update_data = {
            "name": name,
            "description": description,
            "updated_at": datetime.now().isoformat()
        }
        
        try:
            result = db.labels.update_one(
                {"label_id": label_id}, 
                {"$set": update_data}
            )
            
            if result.matched_count == 0:
                return jsonify({"success": False, "error": "æ ‡ç­¾ä¸å­˜åœ¨"}), 404
                
        except Exception as e:
            logger.warning(f"MongoDBæ›´æ–°æ ‡ç­¾å¤±è´¥: {e}")
        
        # æ›´æ–°å†…å­˜ç»“æ„
        for label in LABELS:
            if label.get('label_id') == label_id:
                label['name'] = name
                break
        
        return jsonify({"success": True, "message": "æ ‡ç­¾æ›´æ–°æˆåŠŸ"})
        
    except Exception as e:
        logger.error(f"æ›´æ–°æ ‡ç­¾å¤±è´¥: {e}")
        return jsonify({"success": False, "error": "æ›´æ–°æ ‡ç­¾å¤±è´¥"}), 500

@bp.route('/api/admin/labels/<int:label_id>', methods=['DELETE'])
def delete_label(label_id):
    """è½¯åˆ é™¤æ ‡ç­¾"""
    try:
        # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦è¢«ä½¿ç”¨
        try:
            annotation_count = db.annotations.count_documents({"label_id": label_id})
            if annotation_count > 0:
                return jsonify({
                    "success": False, 
                    "error": f"æ— æ³•åˆ é™¤æ ‡ç­¾ï¼Œä»æœ‰ {annotation_count} ä¸ªæ ‡æ³¨ä½¿ç”¨è¯¥æ ‡ç­¾"
                }), 400
        except Exception:
            pass
        
        # è½¯åˆ é™¤ï¼šæ ‡è®°ä¸ºinactive
        try:
            result = db.labels.update_one(
                {"label_id": label_id}, 
                {"$set": {"active": False, "deleted_at": datetime.now().isoformat()}}
            )
            
            if result.matched_count == 0:
                return jsonify({"success": False, "error": "æ ‡ç­¾ä¸å­˜åœ¨"}), 404
                
        except Exception as e:
            logger.warning(f"MongoDBè½¯åˆ é™¤æ ‡ç­¾å¤±è´¥: {e}")
        
        # ä»å†…å­˜ä¸­ç§»é™¤
        global LABELS
        LABELS = [label for label in LABELS if label.get('label_id') != label_id]
        
        return jsonify({"success": True, "message": "æ ‡ç­¾åˆ é™¤æˆåŠŸ"})
        
    except Exception as e:
        logger.error(f"åˆ é™¤æ ‡ç­¾å¤±è´¥: {e}")
        return jsonify({"success": False, "error": "åˆ é™¤æ ‡ç­¾å¤±è´¥"}), 500
