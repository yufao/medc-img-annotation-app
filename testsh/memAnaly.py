import psutil
import time
import json
from datetime import datetime

class ResourceMonitor:
    def __init__(self):
        self.data = []
    
    def analyze_image_processing_memory(self):
        """åˆ†æå›¾åƒå¤„ç†çš„å†…å­˜éœ€æ±‚ï¼ˆä¸å«AIæ¨¡å‹ï¼‰"""
        # åŒ»å­¦å›¾åƒæ ‡æ³¨çš„å®é™…åœºæ™¯
        scenarios = {
            "DICOMå›¾åƒåŠ è½½": {
                "file_size_mb": 50,  # å…¸å‹CT/MRIåˆ‡ç‰‡
                "processing_multiplier": 3,  # å›¾åƒè§£ç å’Œç¼“å­˜
                "concurrent_users": 8  # 8ä¸ªåŒ»ç”ŸåŒæ—¶æ ‡æ³¨
            },
            "å¤šå±‚å›¾åƒåºåˆ—": {
                "file_size_mb": 200,  # å¤šå±‚åºåˆ—æ–‡ä»¶
                "processing_multiplier": 2.5,  # åºåˆ—åŠ è½½å’Œæ¸²æŸ“
                "concurrent_users": 5
            },
            "æ ‡æ³¨æ•°æ®å¤„ç†": {
                "annotation_data_mb": 20,  # æ ‡æ³¨åæ ‡ã€å½¢çŠ¶æ•°æ®
                "image_overlay_mb": 30,    # å åŠ å±‚æ¸²æŸ“
                "concurrent_users": 10
            },
            "å›¾åƒç¼©æ”¾æ¸²æŸ“": {
                "base_image_mb": 50,
                "zoom_levels": 4,  # 4ä¸ªç¼©æ”¾çº§åˆ«ç¼“å­˜
                "concurrent_users": 8
            }
        }
        
        total_memory_needed = 0
        
        print("=== åŒ»å­¦å›¾åƒæ ‡æ³¨ç³»ç»Ÿå†…å­˜éœ€æ±‚åˆ†æ ===")
        for scenario, config in scenarios.items():
            if "annotation_data_mb" in config:
                # æ ‡æ³¨æ•°æ®å¤„ç†åœºæ™¯
                memory_per_user = config["annotation_data_mb"] + config["image_overlay_mb"]
            elif "zoom_levels" in config:
                # å›¾åƒç¼©æ”¾åœºæ™¯
                memory_per_user = config["base_image_mb"] * config["zoom_levels"]
            else:
                # æ ‡å‡†å›¾åƒå¤„ç†åœºæ™¯
                memory_per_user = config["file_size_mb"] * config["processing_multiplier"]
            
            total_scenario_memory = memory_per_user * config["concurrent_users"]
            total_memory_needed += total_scenario_memory
            
            print(f"{scenario}:")
            print(f"  å•ç”¨æˆ·å†…å­˜éœ€æ±‚: {memory_per_user}MB")
            print(f"  å¹¶å‘ç”¨æˆ·æ•°: {config['concurrent_users']}")
            print(f"  åœºæ™¯æ€»å†…å­˜: {total_scenario_memory}MB")
            print()
        
        # åŠ ä¸Šç³»ç»Ÿå¼€é”€å’ŒWebæœåŠ¡å†…å­˜
        web_service_memory = 512  # Flask + æ•°æ®åº“è¿æ¥æ± ç­‰
        system_overhead = total_memory_needed * 0.4  # 40%ç³»ç»Ÿå¼€é”€ï¼ˆåŒ»å­¦åº”ç”¨ç¨³å®šæ€§è¦æ±‚é«˜ï¼‰
        recommended_memory = (total_memory_needed + system_overhead + web_service_memory) / 1024
        
        print(f"åº”ç”¨æ€»å†…å­˜éœ€æ±‚: {total_memory_needed}MB")
        print(f"WebæœåŠ¡å†…å­˜: {web_service_memory}MB")
        print(f"ç³»ç»Ÿå¼€é”€(40%): {system_overhead}MB")
        print(f"æ¨èå†…å­˜é…ç½®: {recommended_memory:.1f}GB")
        
        return recommended_memory

    def analyze_concurrent_doctor_usage(self):
        """åˆ†æåŒ»ç”Ÿå¹¶å‘ä½¿ç”¨æ¨¡å¼"""
        # åŸºäºå®é™…åŒ»é™¢å·¥ä½œæ¨¡å¼
        usage_patterns = {
            "ä¸Šåˆè¯Šæ–­é«˜å³°": {
                "time_period": "9:00-12:00",
                "concurrent_doctors": 8,
                "avg_session_duration_min": 45,
                "images_per_session": 15
            },
            "ä¸‹åˆå¤æŸ¥æ—¶æ®µ": {
                "time_period": "14:00-17:00", 
                "concurrent_doctors": 6,
                "avg_session_duration_min": 30,
                "images_per_session": 10
            },
            "æ™šé—´ç´§æ€¥ä¼šè¯Š": {
                "time_period": "19:00-22:00",
                "concurrent_doctors": 3,
                "avg_session_duration_min": 60,
                "images_per_session": 20
            }
        }
        
        print("\n=== åŒ»ç”Ÿä½¿ç”¨æ¨¡å¼åˆ†æ ===")
        max_concurrent = 0
        peak_memory_mb = 0
        
        for pattern, data in usage_patterns.items():
            concurrent = data["concurrent_doctors"]
            max_concurrent = max(max_concurrent, concurrent)
            
            # æ¯ä¸ªåŒ»ç”Ÿçš„å†…å­˜ä½¿ç”¨ä¼°ç®—
            memory_per_doctor = (
                50 * 3 +  # å½“å‰æŸ¥çœ‹çš„å›¾åƒ
                20 +       # æ ‡æ³¨æ•°æ®
                30 +       # UIç¼“å­˜
                50         # æµè§ˆå™¨æ¸²æŸ“ç¼“å­˜
            )  # 150MB per doctor
            
            pattern_memory = memory_per_doctor * concurrent
            peak_memory_mb = max(peak_memory_mb, pattern_memory)
            
            print(f"{pattern} ({data['time_period']}):")
            print(f"  å¹¶å‘åŒ»ç”Ÿ: {concurrent}äºº")
            print(f"  å•åŒ»ç”Ÿå†…å­˜: {memory_per_doctor}MB")
            print(f"  æ—¶æ®µå³°å€¼å†…å­˜: {pattern_memory}MB")
            print(f"  å¹³å‡ä¼šè¯æ—¶é•¿: {data['avg_session_duration_min']}åˆ†é’Ÿ")
            print()
        
        print(f"ç³»ç»Ÿå³°å€¼å¹¶å‘: {max_concurrent}äºº")
        print(f"å³°å€¼å†…å­˜éœ€æ±‚: {peak_memory_mb}MB ({peak_memory_mb/1024:.1f}GB)")
        
        return max_concurrent, peak_memory_mb

    def calculate_cpu_requirements(self, max_concurrent_doctors):
        """è®¡ç®—CPUéœ€æ±‚"""
        # åŒ»å­¦å›¾åƒå¤„ç†çš„CPUå¯†é›†æ“ä½œ
        cpu_intensive_operations = {
            "DICOMè§£æ": {"cpu_percent_per_user": 8, "duration_sec": 3},
            "å›¾åƒæ ¼å¼è½¬æ¢": {"cpu_percent_per_user": 15, "duration_sec": 2},
            "æ ‡æ³¨æ¸²æŸ“": {"cpu_percent_per_user": 5, "duration_sec": 1},
            "æ•°æ®åº“æŸ¥è¯¢": {"cpu_percent_per_user": 3, "duration_sec": 0.5},
            "å¹¶å‘å“åº”å¤„ç†": {"cpu_percent_per_user": 10, "duration_sec": 0.2}
        }
        
        print("\n=== CPUéœ€æ±‚åˆ†æ ===")
        total_cpu_percent = 0
        
        for operation, specs in cpu_intensive_operations.items():
            cpu_per_user = specs["cpu_percent_per_user"]
            total_operation_cpu = cpu_per_user * max_concurrent_doctors
            total_cpu_percent += total_operation_cpu
            
            print(f"{operation}:")
            print(f"  å•ç”¨æˆ·CPU: {cpu_per_user}%")
            print(f"  {max_concurrent_doctors}å¹¶å‘CPU: {total_operation_cpu}%")
        
        # è®¡ç®—æ‰€éœ€CPUæ ¸å¿ƒæ•°ï¼ˆä¿æŒ70%åˆ©ç”¨ç‡ï¼‰
        target_utilization = 70
        required_cores = max(4, int((total_cpu_percent / target_utilization) + 0.5))
        
        print(f"\næ€»CPUéœ€æ±‚: {total_cpu_percent}%")
        print(f"ç›®æ ‡åˆ©ç”¨ç‡: {target_utilization}%")
        print(f"æ¨èCPUæ ¸å¿ƒæ•°: {required_cores}æ ¸")
        
        return required_cores

    def generate_recommendations(self, memory_gb, cpu_cores, max_concurrent):
        """ç”Ÿæˆæœ€ç»ˆé…ç½®æ¨è"""
        return {
            "å½“å‰æ¼”ç¤ºç¯å¢ƒ": {
                "cpu_cores": 2,
                "memory_gb": 2,
                "concurrent_users": 2,
                "é€‚ç”¨åœºæ™¯": "åŠŸèƒ½æ¼”ç¤ºã€éªŒæ”¶æµ‹è¯•",
                "é™åˆ¶": ["å¹¶å‘ç”¨æˆ·å°‘", "å¯èƒ½å‡ºç°å¡é¡¿", "ä¸é€‚åˆç”Ÿäº§ä½¿ç”¨"]
            },
            "ç”Ÿäº§ç¯å¢ƒæ¨è": {
                "cpu_cores": cpu_cores,
                "memory_gb": memory_gb,
                "concurrent_users": max_concurrent,
                "é€‚ç”¨åœºæ™¯": "æ­£å¼åŒ»é™¢éƒ¨ç½²",
                "ä¼˜åŠ¿": ["æ”¯æŒ8-10åŒ»ç”Ÿå¹¶å‘", "å“åº”é€Ÿåº¦å¿«", "ç³»ç»Ÿç¨³å®šå¯é "]
            },
            "é…ç½®å¯¹æ¯”": {
                "æ€§èƒ½æå‡": f"CPUæ€§èƒ½æå‡{cpu_cores/2:.1f}å€",
                "å†…å­˜æå‡": f"å†…å­˜å®¹é‡æå‡{memory_gb/2:.1f}å€", 
                "å¹¶å‘æå‡": f"å¹¶å‘èƒ½åŠ›æå‡{max_concurrent/2:.1f}å€"
            }
        }

    def save_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„é…ç½®éœ€æ±‚æŠ¥å‘Š"""
        memory_gb = self.analyze_image_processing_memory()
        max_concurrent, peak_memory_mb = self.analyze_concurrent_doctor_usage()
        cpu_cores = self.calculate_cpu_requirements(max_concurrent)
        
        # å–è¾ƒå¤§å€¼ç¡®ä¿å……è¶³
        final_memory_gb = max(memory_gb, peak_memory_mb/1024 * 1.3)  # 30%å®‰å…¨è¾¹é™…
        final_cpu_cores = max(cpu_cores, 4)  # æœ€å°‘4æ ¸
        
        recommendations = self.generate_recommendations(int(final_memory_gb), final_cpu_cores, max_concurrent)
        
        report = {
            "åˆ†ææ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "é¡¹ç›®": "åŒ»å­¦å›¾åƒæ ‡æ³¨ç³»ç»Ÿ",
            "åˆ†æç»“æœ": {
                "ç†è®ºå†…å­˜éœ€æ±‚": f"{memory_gb:.1f}GB",
                "å®é™…å†…å­˜éœ€æ±‚": f"{final_memory_gb:.1f}GB", 
                "CPUæ ¸å¿ƒéœ€æ±‚": f"{final_cpu_cores}æ ¸",
                "æœ€å¤§å¹¶å‘åŒ»ç”Ÿ": f"{max_concurrent}äºº"
            },
            "é…ç½®æ¨è": recommendations,
            "æˆæœ¬æ•ˆç›Šåˆ†æ": {
                "æ¼”ç¤ºç¯å¢ƒæˆæœ¬": "çº¦300å…ƒ/æœˆ",
                "ç”Ÿäº§ç¯å¢ƒæˆæœ¬": "çº¦1000å…ƒ/æœˆ",
                "æˆæœ¬å·®å¼‚åŸå› ": "ç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´é«˜é…ç½®ä¿è¯åŒ»ç–—ç³»ç»Ÿç¨³å®šæ€§å’Œå“åº”é€Ÿåº¦"
            }
        }
        
        with open('åŒ»å­¦å›¾åƒæ ‡æ³¨ç³»ç»Ÿé…ç½®éœ€æ±‚æŠ¥å‘Š.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°æ€»ç»“
        print("\n" + "="*50)
        print("ğŸ“Š é…ç½®éœ€æ±‚æ€»ç»“")
        print("="*50)
        print(f"æ¼”ç¤ºç¯å¢ƒ: 2æ ¸2GB (å½“å‰) âœ…")
        print(f"ç”Ÿäº§ç¯å¢ƒ: {final_cpu_cores}æ ¸{int(final_memory_gb)}GB (æ¨è) ğŸ¯")
        print(f"ä¸»è¦åŸå› :")
        print(f"  â€¢ æ”¯æŒ{max_concurrent}åŒ»ç”ŸåŒæ—¶æ ‡æ³¨")
        print(f"  â€¢ åŒ»å­¦å›¾åƒæ–‡ä»¶å¤§(50-200MB)")
        print(f"  â€¢ å›¾åƒå¤„ç†å†…å­˜æ”¾å¤§3å€")
        print(f"  â€¢ åŒ»ç–—ç³»ç»Ÿç¨³å®šæ€§è¦æ±‚é«˜")
        print("="*50)
        
        return report

if __name__ == "__main__":
    monitor = ResourceMonitor()
    report = monitor.save_detailed_report()
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: åŒ»å­¦å›¾åƒæ ‡æ³¨ç³»ç»Ÿé…ç½®éœ€æ±‚æŠ¥å‘Š.json")